---
date: 2015/3/12 16:42:12 
layout: post
title: hadoop HA
categories: hadoop
tags:  hadoop
---
## hadoop HDFS HA

hadoop hdfs HA实现方式有种，一种是QJM方式，一种是NFS

QJM方式实现的HA官方地址：
[http://hadoop.apache.org/docs/r2.5.2/hadoop-project-dist/hadoop-hdfs/HDFSHighAvailabilityWithQJM.html](http://hadoop.apache.org/docs/r2.5.2/hadoop-project-dist/hadoop-hdfs/HDFSHighAvailabilityWithQJM.html)


NFS方式实现的HA官方地址：
[http://hadoop.apache.org/docs/r2.5.2/hadoop-project-dist/hadoop-hdfs/HDFSHighAvailabilityWithNFS.html](http://hadoop.apache.org/docs/r2.5.2/hadoop-project-dist/hadoop-hdfs/HDFSHighAvailabilityWithNFS.html)

###QJM方式架构图：

![](/image/hadoop-hdfs-ha.jpg)

* 确保只有一个NameNode提供服务
	Active NameNode与Standby NameNode,同一时刻只应有一个活跃状态提供服务的NameNode.要保障同一时刻只有一个Active NameNode,需要有一定的隔离（fencing)机制。
* Active NameNode与Standby NameNode元数据同步机制
	Standby NameNode应能够实时访问Active NameNode的edits日志，所以可靠日志的共享机制非常重要
* 故障检测
	如果Active NameNode失效或者其依赖的OS,硬件出现故障如果进行检测，这需要FailoverController组件
* 自动故障转移
	故障检测的目的是期望能够快速的自动切换，使得故障不影响NameNode的对外服务。而自动检测这里依赖于FailoverController组件与Zookeeper集群的交互
* Standby NameNode与Active NameNode之间的Block块同步
	NameNode启动时将所有HDFS元数据信息从fsimage和edits中导入内存，元数据更新操作写入edits。但是数据块block信息不存储到文件，是NN启动后与DN实时交互获取的。如果发生故障切换，而新上任的NameNode没有实时的Block信息，依然无法完成服务。所以要求DN的Block信息要同时汇报给所有NameNode
###NameNode HA对外统一访问接口
![](/image/hadoop-ha-1.jpg)
###隔离机制fencing
![](/image/hadoop-ha-2.jpg)
###可靠日志共享
![](/image/hadoop-ha-3.jpg)

###配置NN HA几个组件

1. Active NameNode,Standby NameNode 两台机器硬件配置要一致 （在不同机器）
2. DataNode(不同机器）
3. 以QJM方式,journalNode，轻量级组件，数量为奇数个（2n+1),最多允许N个机器出故障（不同机器）
4. zookeeper（不同机器）
5. ZKFC(对应于NameNode,每个NameNode都有一个）

运行HA后 Secondary NameNode, CheckpointNode, or BackupNode 都不能运行了，不然会报错。

###HA管理命令：
![](/image/hadoop-ha-4.jpg)

	hdfs haadmin
 	DFSHAAdmin [-ns <nameserviceId>]
    [-transitionToActive <serviceId>]
    [-transitionToStandby <serviceId>]
    [-failover [--forcefence] [--forceactive] <serviceId> <serviceId>]
    [-getServiceState <serviceId>]
    [-checkHealth <serviceId>]
    [-help <command>]


